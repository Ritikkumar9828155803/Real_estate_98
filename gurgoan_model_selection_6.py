# -*- coding: utf-8 -*-
"""gurgoan Model Selection#6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15EpgGNL1qt4eYdtvQBU0MSn7tcVJi5dr
"""

import pandas as pd
import numpy as np

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.neural_network import MLPRegressor
from xgboost import XGBRegressor

df=pd.read_csv("/content/Gurgoan_Wrangled_Data_2.csv")

df.sample(7)



"""## Feature Selection :"""

df.isnull().sum()

training_df=df

from sklearn.preprocessing import LabelEncoder
l_encoder=LabelEncoder()
training_df['possession']=l_encoder.fit_transform(training_df['possession'])
training_df['sector']=l_encoder.fit_transform(training_df['sector'])
training_df['noOfOpenSides']=l_encoder.fit_transform(training_df['noOfOpenSides'])

"""## 1- Correlation"""

fi_df1=training_df.corr()['price'].iloc[1:].to_frame().reset_index().rename(columns={'index':'feature','price':'corr_coeff'})
fi_df1

"""## RFE :"""

x_label=training_df.drop(['price'],axis=1)
y_label=training_df['price']

x_label.isnull().sum()

from sklearn.ensemble import RandomForestRegressor
rf_label=RandomForestRegressor(n_estimators=100, random_state=20)
rf_label.fit(x_label,y_label)

fi_df2 = pd.DataFrame({'feature':x_label.columns,'rf_importance':rf_label.feature_importances_}).sort_values(by='rf_importance',ascending=False)

fi_df2

"""## Gradient Boosting Regressor :"""

y_label.isnull().sum(),x_label.isnull().sum()

from sklearn.ensemble import GradientBoostingRegressor
gb_label=GradientBoostingRegressor()
gb_label.fit(x_label,y_label)

fi_df3 = pd.DataFrame({'feature':x_label.columns,'gb_importance':gb_label.feature_importances_}).sort_values(by='gb_importance',ascending=False)
fi_df3

"""## Permutation Importance"""

from sklearn.inspection import permutation_importance
from sklearn.model_selection import train_test_split

x_train_label,x_test_label,y_train_label,y_test_label=train_test_split(x_label,y_label,test_size=0.2,random_state=3)


rf_label=RandomForestRegressor(n_estimators=100,random_state=34)
rf_label.fit(x_train_label,y_train_label)

perm_importance=permutation_importance(rf_label,x_test_label,y_test_label,n_repeats=30,random_state=5)

fi_df4=pd.DataFrame({'feature':x_label.columns,'perm_importance':perm_importance.importances_mean}).sort_values(by='perm_importance',ascending=False)

"""## Lasso"""

from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler

scaler=StandardScaler()
x_scaled=scaler.fit_transform(x_label)
lasso=Lasso(alpha=0.01,random_state=8)
lasso.fit(x_scaled,y_label)

fi_df5=pd.DataFrame({'feature':x_label.columns,'lasso_coeff':lasso.coef_}).sort_values(by='lasso_coeff',ascending=False)
fi_df5

"""#RFE"""

from sklearn.feature_selection import RFE

# Initialize the base estimator
estimator = RandomForestRegressor()

# Apply RFE on the label-encoded and standardized training data
selector_label = RFE(estimator, n_features_to_select=x_label.shape[1], step=1)
selector_label = selector_label.fit(x_label, y_label)

# Get the selected features based on RFE
selected_features = x_label.columns[selector_label.support_]

# Extract the coefficients for the selected features from the underlying linear regression model
selected_coefficients = selector_label.estimator_.feature_importances_

# Organize the results into a DataFrame
fi_df6 = pd.DataFrame({
    "feature": selected_features,
    "rfe_score": selected_coefficients
}).sort_values(by="rfe_score", ascending=False)

fi_df6

"""# Linear Regression"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(x_scaled, y_label)

# Extract coefficients
fi_df7 = pd.DataFrame({
    "feature": x_label.columns,
    "reg_coeffs": lin_reg.coef_
}).sort_values(by="reg_coeffs", ascending=False)

fi_df7

"""## SHAP"""

! pip install shap

import shap


# Assuming X_label and y_label are defined elsewhere in your code

# Compute SHAP values using the trained Random Forest model
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(x_label, y_label)

explainer = shap.TreeExplainer(rf)
shap_values = explainer.shap_values(x_label)

# Summing the absolute SHAP values across all samples to get an overall measure of feature importance
shap_sum = np.abs(shap_values).mean(axis=0)

shap_values

fi_df8=pd.DataFrame({'feature':x_label.columns,'SHAP_score':np.abs(shap_values).mean(axis=0)}).sort_values(by='SHAP_score',ascending=False)

merged_feature_selection_results=pd.merge(fi_df1,fi_df2,on='feature').merge(fi_df3,on='feature').merge(fi_df4,on='feature').merge(fi_df5,on='feature').merge(fi_df6,on='feature').merge(fi_df7,on='feature').merge(fi_df8,on='feature').set_index('feature')

merged_feature_selection_results

merged_feature_selection_results=merged_feature_selection_results.divide(merged_feature_selection_results.sum(axis=0),axis=1)

merged_feature_selection_results[['rf_importance'	,'gb_importance','perm_importance','rfe_score','SHAP_score']].mean(axis=1).sort_values(ascending=True)

x_label

"""## Features vs Models"""

from sklearn.model_selection import cross_val_score

rf= RandomForestRegressor(n_estimators=100,random_state=6)

score=cross_val_score(rf,x_label,y_label,cv=5,scoring='r2')

score.mean() # R_2 Score-1

x_label.columns

"""# After deselecting non important columns

rf=RandomForestRegressor(n_estimators=100,random_state=3)

scores=cross_val_score(rf,x_label.drop(columns=['Maintenance_Staff', 'Water_Storage', 'Vaastu_Compliant',
       'Rain_Water_Harvesting']),y_label,cv=5,scoring='r2')
scores.mean()


export_df_2=x_label.drop(columns=['Maintenance_Staff', 'Water_Storage', 'Vaastu_Compliant',
       'Rain_Water_Harvesting'])
"""

# After deselecting non important columns

rf=RandomForestRegressor(n_estimators=100,random_state=3)

scores=cross_val_score(rf,x_label.drop(columns=[
       'Maintenance_Staff', 'Water_Storage', 'Vaastu_Compliant',
       'Rain_Water_Harvesting','Park', 'School', 'College'

    ]),y_label,cv=5,scoring='r2')
#.drop(columns=[  'Vaastu_Compliant', 'College','Mall','Hospital','School']

scores.mean() # R_2 Score-2

#export_df_2=x_label.drop(columns=['possession', 'Maintenance_Staff','Water_Storage', 'Vaastu_Compliant', 'Rain_Water_Harvesting', 'College', 'Hospital','Airport','Mall','Metro'])

df2=pd.read_csv("/content/Gurgoan_Wrangled_data.csv")
df2.columns

#df2=df2.drop(columns=['Maintenance_Staff', 'Water_Storage', 'Vaastu_Compliant','Rain_Water_Harvesting', 'Mall','Metro','Park' ,'College','Hospital', 'Airport'],axis=1)

x_label=df2.drop(['price','School','College','Park','Maintenance_Staff', 'Water_Storage',
       'Vaastu_Compliant', 'Rain_Water_Harvesting'],axis=1)
y_label=df2['price']

from sklearn.model_selection import KFold,cross_val_score
from sklearn.preprocessing import OneHotEncoder,StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.compose import ColumnTransformer
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline

y_transferred=np.log1p(y_label)

columns_to_encode=['sector',	'noOfOpenSides',	'possession',		'Metro'	,		'Hospital',	'Shrine',	'Mall',	'Airport']

preprocessor=ColumnTransformer(transformers=[('num',StandardScaler(),['area','Rating','price_per_sqft' ]),('cat',OneHotEncoder(handle_unknown='infrequent_if_exist'),columns_to_encode)],remainder='passthrough')

pipeline=Pipeline([('preprocessor',preprocessor),('regressor',LinearRegression())])

pipeline_2=Pipeline([('preprocessor',preprocessor),('regressor',SVR(kernel='rbf'))])

kfold=KFold(n_splits=10,shuffle=True,random_state=3)
score=cross_val_score(pipeline,x_label,y_transferred,cv=kfold,scoring='r2')
score_2=cross_val_score(pipeline_2,x_label,y_transferred,cv=kfold,scoring='r2')

score.mean(),score_2.mean() # R_2 Score-3

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x_label,y_transferred,test_size=0.2,random_state=5)

pipeline_2.fit(x_train,y_train)

y_pred=pipeline_2.predict(x_test)

y_pred=np.log1p(y_pred)
y_test=np.log1p(y_test)

from sklearn.metrics import mean_absolute_error

print(mean_absolute_error(y_test,y_pred)) # Error-1

"""## Ordinal Encoding"""

from sklearn.preprocessing import OrdinalEncoder

# Creating a column transformer for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['area','Rating','price_per_sqft']),
        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), columns_to_encode)
    ],
    remainder='passthrough'
)

# Creating a pipeline
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# K-fold cross-validation
kfold = KFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(pipeline, x_label, y_transferred, cv=kfold, scoring='r2')

scores.mean(),scores.std() #Error-2

X_train, X_test, y_train, y_test = train_test_split(x_label,y_transferred,test_size=0.2,random_state=42)

pipeline.fit(X_train,y_train)

y_pred = pipeline.predict(X_test)
y_pred = np.expm1(y_pred)

mean_absolute_error(np.expm1(y_test),y_pred) # Error-3

def scorer(model_name, model):

    output = []

    output.append(model_name)

    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', model)
    ])

    # K-fold cross-validation
    kfold = KFold(n_splits=10, shuffle=True, random_state=42)
    scores = cross_val_score(pipeline, x_label, y_transferred, cv=kfold, scoring='r2')

    output.append(scores.mean())

    X_train, X_test, y_train, y_test = train_test_split(x_label,y_transferred,test_size=0.2,random_state=42)

    pipeline.fit(X_train,y_train)

    y_pred = pipeline.predict(X_test)

    y_pred = np.expm1(y_pred)

    output.append(mean_absolute_error(np.expm1(y_test),y_pred))

    return output

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.neural_network import MLPRegressor
from xgboost import XGBRegressor

model_dict = {
    'linear_reg':LinearRegression(),
    'svr':SVR(),
    'ridge':Ridge(),
    'LASSO':Lasso(),
    'decision tree': DecisionTreeRegressor(),
    'random forest':RandomForestRegressor(),
    'extra trees': ExtraTreesRegressor(),
    'gradient boosting': GradientBoostingRegressor(),
    'adaboost': AdaBoostRegressor(),
    'mlp': MLPRegressor(),
    'xgboost':XGBRegressor()
}

model_output = []
for model_name,model in model_dict.items():
    model_output.append(scorer(model_name, model))

model_output

model_df = pd.DataFrame(model_output, columns=['name','r2','mae'])

model_df.sort_values(['mae'])

"""## OneHotEncoding & Ordinal Encoding"""

df.columns

columns_to_encode=['Metro'	,		'Hospital',	'Shrine',	'Mall',	'Airport']

# Creating a column transformer for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['area','Rating','price_per_sqft']),
        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), columns_to_encode),
        ('cat1',OneHotEncoder(handle_unknown='infrequent_if_exist'),['sector','noOfOpenSides','possession'])
    ],
    remainder='passthrough'
)

# Creating a pipeline
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

df2.columns

X=df2.drop([ 'Maintenance_Staff', 'Water_Storage',
       'Vaastu_Compliant', 'Rain_Water_Harvesting',
       'School', 'College','Park','price'],axis=1)

y_transformed=y_transferred

# K-fold cross-validation
kfold = KFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(pipeline, X, y_transferred, cv=kfold, scoring='r2')

scores.mean() # R_2 Score-4

scores.std()

X_train, X_test, y_train, y_test = train_test_split(X,y_transformed,test_size=0.2,random_state=42)

pipeline.fit(X_train,y_train)

y_pred = pipeline.predict(X_test)

y_pred = np.expm1(y_pred)

mean_absolute_error(np.expm1(y_test),y_pred) #Error-4

def scorer(model_name, model):

    output = []

    output.append(model_name)

    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', model)
    ])

    # K-fold cross-validation
    kfold = KFold(n_splits=10, shuffle=True, random_state=42)
    scores = cross_val_score(pipeline, X, y_transformed, cv=kfold, scoring='r2')

    output.append(scores.mean())

    X_train, X_test, y_train, y_test = train_test_split(X,y_transformed,test_size=0.2,random_state=42)

    pipeline.fit(X_train,y_train)

    y_pred = pipeline.predict(X_test)

    y_pred = np.expm1(y_pred)

    output.append(mean_absolute_error(np.expm1(y_test),y_pred))

    return output

model_dict = {
    'linear_reg':LinearRegression(),
    'svr':SVR(),
    'ridge':Ridge(),
    'LASSO':Lasso(),
    'decision tree': DecisionTreeRegressor(),
    'random forest':RandomForestRegressor(),
    'extra trees': ExtraTreesRegressor(),
    'gradient boosting': GradientBoostingRegressor(),
    'adaboost': AdaBoostRegressor(),
    'mlp': MLPRegressor(),
    'xgboost':XGBRegressor()
}

model_output = []
for model_name,model in model_dict.items():
    model_output.append(scorer(model_name, model))

model_df = pd.DataFrame(model_output, columns=['name','r2','mae'])

model_df.sort_values(['mae'])

"""## OneHotEncoding With PCA

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['area','Rating']),
        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), columns_to_encode),
        ('cat1',OneHotEncoder(handle_unknown='infrequent_if_exist'),['sector','noOfOpenSides'])
    ],
    remainder='passthrough'
)




from sklearn.decomposition import PCA




pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('pca', PCA(n_components=0.95)),
    ('regressor', LinearRegression())
])




kfold = KFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(pipeline, X, y_transformed, cv=kfold, scoring='r2')
scores.mean()   


def scorer(model_name, model):

    output = []

    output.append(model_name)

    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('pca', PCA(n_components=0.95)),
        ('regressor', model)
    ])

    
    kfold = KFold(n_splits=10, shuffle=True, random_state=42)
    scores = cross_val_score(pipeline, X, y_transformed, cv=kfold, scoring='r2')

    output.append(scores.mean())

    X_train, X_test, y_train, y_test = train_test_split(X,y_transformed,test_size=0.2,random_state=42)

    pipeline.fit(X_train,y_train)

    y_pred = pipeline.predict(X_test)

    y_pred = np.expm1(y_pred)

    output.append(mean_absolute_error(np.expm1(y_test),y_pred))

    return output   






model_dict = {
    'linear_reg':LinearRegression(),
    'svr':SVR(),
    'ridge':Ridge(),
    'LASSO':Lasso(),
    'decision tree': DecisionTreeRegressor(),
    'random forest':RandomForestRegressor(),
    'extra trees': ExtraTreesRegressor(),
    'gradient boosting': GradientBoostingRegressor(),
    'adaboost': AdaBoostRegressor(),
    'mlp': MLPRegressor(),
    'xgboost':XGBRegressor()
}



model_output = []
for model_name,model in model_dict.items():
    model_output.append(scorer(model_name, model))




model_df = pd.DataFrame(model_output, columns=['name','r2','mae'])
model_df.sort_values(['mae'])

## Target Encoder

!pip install category_encoders


import category_encoders as ce




preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['areaWithType','Rating']),
        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), columns_to_encode),
        ('cat1',OneHotEncoder(handle_unknown='infrequent_if_exist'),['noOfOpenSides']),
        ('target_enc', ce.TargetEncoder(handle_unknown='value'), ['sector'])
    ],
    remainder='passthrough'
)   


scores.mean(),scores.std()



pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])   


kfold = KFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(pipeline, X, y_transformed, cv=kfold, scoring='r2')



def scorer(model_name, model):

    output = []

    output.append(model_name)

    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', model)
    ])

    
    kfold = KFold(n_splits=10, shuffle=True, random_state=42)
    scores = cross_val_score(pipeline, X, y_transformed, cv=kfold, scoring='r2')

    output.append(scores.mean())

    X_train, X_test, y_train, y_test = train_test_split(X,y_transformed,test_size=0.2,random_state=42)

    pipeline.fit(X_train,y_train)

    y_pred = pipeline.predict(X_test)

    y_pred = np.expm1(y_pred)

    output.append(mean_absolute_error(np.expm1(y_test),y_pred))

    return output  



model_dict = {
    'linear_reg':LinearRegression(),
    'svr':SVR(),
    'ridge':Ridge(),
    'LASSO':Lasso(),
    'decision tree': DecisionTreeRegressor(),
    'random forest':RandomForestRegressor(),
    'extra trees': ExtraTreesRegressor(),
    'gradient boosting': GradientBoostingRegressor(),
    'adaboost': AdaBoostRegressor(),
    'mlp': MLPRegressor(),
    'xgboost':XGBRegressor()
}  



model_output = []
for model_name,model in model_dict.items():
    model_output.append(scorer(model_name, model))




model_df = pd.DataFrame(model_output, columns=['name','r2','mae'])
model_df.sort_values(['mae'])

## Hyperparameter Tuning
"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'regressor__n_estimators': [50, 100, 200, 300],
    'regressor__max_depth': [None, 10, 20, 30],
    'regressor__max_samples':[0.1, 0.25, 0.5, 1.0],
    'regressor__max_features': ['auto', 'sqrt']
}

! pip install category_encoders

import category_encoders as ce

columns_to_encode=['Metro',
       'Hospital', 'Shrine', 'Mall', 'Airport']

# Creating a column transformer for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['area','Rating','price_per_sqft']),
        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), columns_to_encode),
        ('cat1',OneHotEncoder(handle_unknown='infrequent_if_exist'),['noOfOpenSides','possession']),
        ('target_enc', ce.TargetEncoder(handle_unknown='value'), ['sector'])
    ],
    remainder='passthrough'
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor())
])

kfold = KFold(n_splits=10, shuffle=True, random_state=42)

from sklearn.model_selection import GridSearchCV

search = GridSearchCV(pipeline, param_grid, cv=kfold, scoring='r2', n_jobs=-1, verbose=4)

search.fit(X, y_transformed)

final_pipe = search.best_estimator_

search.best_params_

search.best_score_

final_pipe.fit(X,y_transformed)

"""## Expoting the model"""

columns_to_encode=['Metro'	,		'Hospital',	'Shrine',	'Mall',	'Airport']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['area','Rating','price_per_sqft']),
        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), columns_to_encode),
        ('cat1',OneHotEncoder(handle_unknown='infrequent_if_exist'),['sector','noOfOpenSides','possession'])
    ],
    remainder='passthrough'
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(n_estimators=500))
])

pipeline.fit(X,y_transformed)

import pickle

with open('pipeline.pkl', 'wb') as file:
    pickle.dump(pipeline, file)

with open('df.pkl', 'wb') as file:
         pickle.dump(X, file)

X

"""Trying out the predictions"""

X.columns

X.iloc[0].values

data = [['sector 50', 90.84, 1.0, 'undefined', 0.005,
       4.0, 1, 1, 1, 1, 1
]]
columns = ['sector',  'area', 'noOfOpenSides', 'possession',
       'price_per_sqft', 'Rating', 'Metro', 'Hospital', 'Shrine', 'Mall',
       'Airport']

# Convert to DataFrame
one_df = pd.DataFrame(data, columns=columns)

one_df

np.expm1(pipeline.predict(one_df))

X.dtypes

sorted(X['sector'].unique().tolist())

from google.colab import files

files.download("df.pkl")

files.download("pipeline.pkl")

